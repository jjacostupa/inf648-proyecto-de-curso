{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3K_2OH9jKm9"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4WflDW4oEYr",
        "outputId": "afdd8207-54b6-47de-f822-287fc684216c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P1fMwohijKnB"
      },
      "outputs": [],
      "source": [
        "# Código obtenido desde https://archive.ics.uci.edu/dataset/579/myocardial+infarction+complications\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Extraer dataset\n",
        "myocardial_infarction_complications = fetch_ucirepo(id=579);\n",
        "\n",
        "# Data (como DataFrames de Pandas)\n",
        "X = myocardial_infarction_complications.data.features\n",
        "y = myocardial_infarction_complications.data.targets\n",
        "\n",
        "# Metadata\n",
        "# print(myocardial_infarction_complications.metadata)\n",
        "\n",
        "# Información de variables\n",
        "# print(myocardial_infarction_complications.variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKC-prO6jKnC"
      },
      "source": [
        "## Ingeniería de variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QUNVPc2GjKnC"
      },
      "outputs": [],
      "source": [
        "# Construcción de variables y target\n",
        "X_1 = X.copy()\n",
        "X_1 = X_1.fillna(-1)\n",
        "\n",
        "y_1 = y['LET_IS']!=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pZHhOTZsjKnD"
      },
      "outputs": [],
      "source": [
        "# Selección de variables: Se utiliza un Arbol de decisión que busque identificar todas las variables necesarias\n",
        "# para identificar completamente cada elemento del target.\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "feature_selection_model = DecisionTreeClassifier(random_state=123)\n",
        "feature_selection_model.fit(X_1, y_1)\n",
        "\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X_1.columns,\n",
        "    'Importance': feature_selection_model.feature_importances_\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AnlH6JJjKnD",
        "outputId": "691e6342-61a3-43d6-a21d-98cb051c4985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha reducido el número de variables de 111 a 58.\n"
          ]
        }
      ],
      "source": [
        "# Las variables que no tienen importancia 0, se descartan.\n",
        "features_to_delete = feature_importances.query('Importance==0')['Feature'].values\n",
        "X_1.drop(columns=features_to_delete, inplace=True)\n",
        "print(f'Se ha reducido el número de variables de {X.shape[1]} a {X_1.shape[1]}.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtLAlInbrCV_",
        "outputId": "b9fc53c3-812b-4ce1-98b4-43fa60cecafe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForest"
      ],
      "metadata": {
        "id": "9eqJmQ9xclN0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChNETKPRjKnE",
        "outputId": "b3cfa2db-2939-4db9-fc57-1f79ad3c0bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-24 18:15:17,117] A new study created in memory with name: no-name-6a331a89-0ead-4a40-8427-c8517e396a89\n",
            "[I 2024-06-24 18:15:27,148] Trial 0 finished with value: 0.8955935541501873 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 121, 'rf_min_samples_leaf': 20, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:28,985] Trial 1 finished with value: 0.767786055252772 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 48, 'rf_min_samples_leaf': 90, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:36,559] Trial 2 finished with value: 0.8950814719085768 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, 'rf_n_estimators': 234, 'rf_min_samples_leaf': 7, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:37,905] Trial 3 finished with value: 0.8897918242793359 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 46, 'rf_min_samples_leaf': 40, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:44,513] Trial 4 finished with value: 0.767786055252772 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 324, 'rf_min_samples_leaf': 81, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:49,766] Trial 5 finished with value: 0.8950814719085768 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 4, 'rf_n_estimators': 281, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:50,182] Trial 6 finished with value: 0.8952872549993189 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, 'rf_n_estimators': 26, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:50,766] Trial 7 finished with value: 0.884748119798153 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 39, 'rf_min_samples_leaf': 27, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:52,616] Trial 8 finished with value: 0.8950814719085768 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 150, 'rf_min_samples_leaf': 30, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:53,286] Trial 9 finished with value: 0.888294420555801 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7, 'rf_n_estimators': 49, 'rf_min_samples_leaf': 31, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:54,758] Trial 10 finished with value: 0.8950814719085768 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 108, 'rf_min_samples_leaf': 12, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:55,112] Trial 11 finished with value: 0.894231031124052 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 3, 'rf_n_estimators': 21, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.8955935541501873.\n",
            "[I 2024-06-24 18:15:56,557] Trial 12 finished with value: 0.9030619309016412 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 99, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 12 with value: 0.9030619309016412.\n",
            "[I 2024-06-24 18:15:57,725] Trial 13 finished with value: 0.8959177590784492 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 84, 'rf_min_samples_leaf': 13, 'rf_criterion': 'entropy'}. Best is trial 12 with value: 0.9030619309016412.\n",
            "[I 2024-06-24 18:15:58,890] Trial 14 finished with value: 0.8959177590784492 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 76, 'rf_min_samples_leaf': 9, 'rf_criterion': 'entropy'}. Best is trial 12 with value: 0.9030619309016412.\n",
            "[I 2024-06-24 18:16:01,001] Trial 15 finished with value: 0.9034177315953216 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 76, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 15 with value: 0.9034177315953216.\n",
            "[I 2024-06-24 18:16:05,035] Trial 16 finished with value: 0.9030619309016412 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 193, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 15 with value: 0.9034177315953216.\n",
            "[I 2024-06-24 18:16:06,106] Trial 17 finished with value: 0.8995900503142258 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 74, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 15 with value: 0.9034177315953216.\n",
            "[I 2024-06-24 18:16:12,436] Trial 18 finished with value: 0.898997494838075 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 483, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 15 with value: 0.9034177315953216.\n",
            "[I 2024-06-24 18:16:15,293] Trial 19 finished with value: 0.9007450437315555 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 164, 'rf_min_samples_leaf': 6, 'rf_criterion': 'entropy'}. Best is trial 15 with value: 0.9034177315953216.\n",
            "[I 2024-06-24 18:16:17,287] Trial 20 finished with value: 0.9040853521515075 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 73, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 20 with value: 0.9040853521515075.\n",
            "[I 2024-06-24 18:16:18,797] Trial 21 finished with value: 0.9042746615844688 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 61, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 21 with value: 0.9042746615844688.\n",
            "[I 2024-06-24 18:16:19,810] Trial 22 finished with value: 0.9023100938067559 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 63, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 21 with value: 0.9042746615844688.\n",
            "[I 2024-06-24 18:16:20,357] Trial 23 finished with value: 0.9031472167449912 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 33, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 21 with value: 0.9042746615844688.\n",
            "[I 2024-06-24 18:16:21,314] Trial 24 finished with value: 0.9046652859515717 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 61, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:22,266] Trial 25 finished with value: 0.8969280861355822 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 65, 'rf_min_samples_leaf': 9, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:23,134] Trial 26 finished with value: 0.9015076946432264 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 58, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:23,767] Trial 27 finished with value: 0.9004909088798966 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 36, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:25,222] Trial 28 finished with value: 0.8809762816556166 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 121, 'rf_min_samples_leaf': 57, 'rf_criterion': 'log_loss'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:25,737] Trial 29 finished with value: 0.8898767339901884 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 28, 'rf_min_samples_leaf': 19, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:27,095] Trial 30 finished with value: 0.8967018958677878 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 92, 'rf_min_samples_leaf': 9, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:27,967] Trial 31 finished with value: 0.9036320669444837 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 55, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:29,090] Trial 32 finished with value: 0.9040966075576504 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 56, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:30,310] Trial 33 finished with value: 0.9022063422182967 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 43, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:31,609] Trial 34 finished with value: 0.8979604973697676 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 49, 'rf_min_samples_leaf': 7, 'rf_criterion': 'log_loss'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:34,417] Trial 35 finished with value: 0.8994435754711055 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 137, 'rf_min_samples_leaf': 6, 'rf_criterion': 'entropy'}. Best is trial 24 with value: 0.9046652859515717.\n",
            "[I 2024-06-24 18:16:35,440] Trial 36 finished with value: 0.9048269290984438 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 66, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 36 with value: 0.9048269290984438.\n",
            "[I 2024-06-24 18:16:36,308] Trial 37 finished with value: 0.9013869413342281 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 56, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial 36 with value: 0.9048269290984438.\n",
            "[I 2024-06-24 18:16:37,003] Trial 38 finished with value: 0.9022595317381118 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 42, 'rf_min_samples_leaf': 4, 'rf_criterion': 'log_loss'}. Best is trial 36 with value: 0.9048269290984438.\n",
            "[I 2024-06-24 18:16:37,555] Trial 39 finished with value: 0.899456237934644 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 31, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial 36 with value: 0.9048269290984438.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenTrial(number=36, state=TrialState.COMPLETE, values=[0.9048269290984438], datetime_start=datetime.datetime(2024, 6, 24, 18, 16, 34, 419044), datetime_complete=datetime.datetime(2024, 6, 24, 18, 16, 35, 440012), params={'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 66, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'classifier': CategoricalDistribution(choices=('RandomForest',)), 'rf_max_depth': IntDistribution(high=15, log=False, low=3, step=1), 'rf_n_estimators': IntDistribution(high=500, log=True, low=20, step=1), 'rf_min_samples_leaf': IntDistribution(high=100, log=True, low=3, step=1), 'rf_criterion': CategoricalDistribution(choices=('entropy', 'gini', 'log_loss'))}, trial_id=36, value=None)\n"
          ]
        }
      ],
      "source": [
        "# Adaptado de https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_simple.py\n",
        "\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"RandomForest\"])\n",
        "    if classifier_name == \"RandomForest\":\n",
        "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 3, 15, log=False)\n",
        "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 20, 500, log=True)\n",
        "        rf_min_samples_leaf = trial.suggest_int(\"rf_min_samples_leaf\", 3, 100, log=True)\n",
        "        rf_criterion = trial.suggest_categorical(\"rf_criterion\", [\"entropy\",\"gini\",\"log_loss\"])\n",
        "        classifier_obj = RandomForestClassifier(\n",
        "            max_depth=rf_max_depth,\n",
        "            n_estimators=rf_n_estimators,\n",
        "            min_samples_leaf=rf_min_samples_leaf,\n",
        "            criterion=rf_criterion,\n",
        "            random_state=123,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "    score = cross_val_score(classifier_obj, X_1, y_1, n_jobs=-1, cv=5, scoring='f1_weighted')\n",
        "    f1_weighted = score.mean()\n",
        "    return f1_weighted\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=40)\n",
        "print(study.best_trial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0awCOSWrjKnE",
        "outputId": "b8bb32a1-4ea2-4b35-e70b-01834054c686"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier': 'RandomForest',\n",
              " 'rf_max_depth': 13,\n",
              " 'rf_n_estimators': 66,\n",
              " 'rf_min_samples_leaf': 3,\n",
              " 'rf_criterion': 'entropy'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Mejores parámetros\n",
        "study.best_trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ8qKgmSjKnE",
        "outputId": "c717262f-d0a3-492c-f368-44ee87c6a089"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1700, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqevnRxvjKnE"
      },
      "source": [
        "## Validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZSai0k66jKnF",
        "outputId": "2b8d0eda-828b-450d-df83-0ec1582ba827",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 ponderado: 0.906. Garces et. al. : 0.900\n",
            "Precisión: 0.921. Garces et. al. : 0.899\n",
            "Recall: 0.919. Garces et. al. : 0.903\n",
            "Accuracy: 0.919. Garces et. al. : 0.903\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "N_FOLDS = 5\n",
        "\n",
        "kf = KFold(n_splits=N_FOLDS, random_state=123, shuffle=True)\n",
        "y_hat_rf = np.zeros(len(X_1))\n",
        "\n",
        "params = {\n",
        "    'max_depth': study.best_trial.params['rf_max_depth'],\n",
        "    'n_estimators': study.best_trial.params['rf_n_estimators'],\n",
        "    'min_samples_leaf': study.best_trial.params['rf_min_samples_leaf'],\n",
        "    'criterion': study.best_trial.params['rf_criterion'],\n",
        "    'n_jobs': -1,\n",
        "    'random_state': 123,\n",
        "}\n",
        "\n",
        "model = RandomForestClassifier(**params)\n",
        "# Se entrena para guardar el artefacto\n",
        "model.fit(X_1, y_1)\n",
        "\n",
        "auc_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='roc_auc')\n",
        "wF1_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='f1_weighted')\n",
        "precision_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='precision_weighted')\n",
        "recall_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='recall_weighted')\n",
        "accuracy_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='accuracy')\n",
        "\n",
        "print(f'F1 ponderado: {np.round(wF1_score.mean(), 3)}. Garces et. al. : 0.900')\n",
        "print(f'Precisión: {np.round(precision_score.mean(), 3)}. Garces et. al. : 0.899')\n",
        "print(f'Recall: {np.round(recall_score.mean(), 3)}. Garces et. al. : 0.903')\n",
        "print(f'Accuracy: {np.round(accuracy_score.mean(), 3)}. Garces et. al. : 0.903')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresion logistica"
      ],
      "metadata": {
        "id": "VOm4DIDdcUko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptado de https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_simple.py\n",
        "\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"LogisticRegression\"])\n",
        "\n",
        "    if classifier_name == \"LogisticRegression\":\n",
        "        r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
        "        c = trial.suggest_float('C', 1e-10, 1000, log=True)\n",
        "        classifier_obj =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
        "\n",
        "    score = cross_val_score(classifier_obj, X_1, y_1, n_jobs=-1, cv=5, scoring='f1_weighted')\n",
        "    f1_weighted = score.mean()\n",
        "    return f1_weighted\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=40)\n",
        "print(study.best_trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkAqmL_YcSF-",
        "outputId": "8acd9b9a-5d04-4af6-9583-d353f41f6d07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-24 18:20:49,910] A new study created in memory with name: no-name-55e74e55-2417-4d11-b341-6b5d70408d5e\n",
            "[I 2024-06-24 18:20:53,449] Trial 0 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.09812523882327084, 'C': 3.5411827889726974e-06}. Best is trial 0 with value: 0.767786055252772.\n",
            "[I 2024-06-24 18:21:35,480] Trial 1 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.8659950064783097, 'C': 440.1684308109714}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:21:35,615] Trial 2 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.05170865171025918, 'C': 2.7252933423096006e-09}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:22:15,374] Trial 3 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.6523167435173035, 'C': 104.87561752936534}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:22:50,629] Trial 4 finished with value: 0.8698548767794186 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.4851736671141267, 'C': 1.266373062690077}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:22:50,749] Trial 5 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.6800761503145313, 'C': 1.6993754803437034e-09}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:23:04,402] Trial 6 finished with value: 0.7663146574763318 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.09466680789374127, 'C': 0.0005035464498233091}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:23:18,306] Trial 7 finished with value: 0.8417077527428237 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.1298763829841847, 'C': 0.015163817249835076}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:23:50,755] Trial 8 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.5461856834937123, 'C': 0.0005207312260388378}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:24:22,746] Trial 9 finished with value: 0.7602378853917993 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.9451765232865391, 'C': 0.0026359319681889598}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:24:59,398] Trial 10 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.9921686971079948, 'C': 849.8287079780954}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:25:35,634] Trial 11 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.7530523635807762, 'C': 562.929588030473}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:26:10,808] Trial 12 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.7957704487282508, 'C': 11.821785060133543}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:26:48,941] Trial 13 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.36680396644500535, 'C': 1.4595064174281616}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:27:23,593] Trial 14 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.8461401056498753, 'C': 23.978064793606215}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:27:23,675] Trial 15 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.6285174085081195, 'C': 3.346345702065595e-06}. Best is trial 1 with value: 0.870662355870542.\n",
            "[I 2024-06-24 18:27:56,345] Trial 16 finished with value: 0.8738129492848735 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.28414036410051857, 'C': 0.21267858232500833}. Best is trial 16 with value: 0.8738129492848735.\n",
            "[I 2024-06-24 18:28:22,170] Trial 17 finished with value: 0.8729095068600852 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.3281451756864515, 'C': 0.07518043264427698}. Best is trial 16 with value: 0.8738129492848735.\n",
            "[I 2024-06-24 18:28:45,858] Trial 18 finished with value: 0.8729095068600852 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.2532031800602275, 'C': 0.06568524087195508}. Best is trial 16 with value: 0.8738129492848735.\n",
            "[I 2024-06-24 18:28:46,411] Trial 19 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.2867796984120668, 'C': 6.121897878559202e-06}. Best is trial 16 with value: 0.8738129492848735.\n",
            "[I 2024-06-24 18:29:17,997] Trial 20 finished with value: 0.8738129492848735 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.39794967489959576, 'C': 0.2147128936810162}. Best is trial 16 with value: 0.8738129492848735.\n",
            "[I 2024-06-24 18:29:46,410] Trial 21 finished with value: 0.875982754969993 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.3793805435646027, 'C': 0.13491340847784616}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:30:21,644] Trial 22 finished with value: 0.8736451117060131 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.44257370479191044, 'C': 0.6364050368541354}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:30:41,375] Trial 23 finished with value: 0.8661632861221591 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.19509637829975907, 'C': 0.036351022399086975}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:30:51,756] Trial 24 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.37503442947762144, 'C': 3.244824016747496e-05}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:31:27,993] Trial 25 finished with value: 0.8721196589785485 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.1996934128007591, 'C': 0.5491439542943878}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:31:30,278] Trial 26 finished with value: 0.7651151899937069 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.4409281056764852, 'C': 0.005326120116883896}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:32:08,612] Trial 27 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.5254780798121477, 'C': 9.396409716776978}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:32:39,530] Trial 28 finished with value: 0.8743399361591531 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.3851702009314535, 'C': 0.20258263561759451}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:33:15,297] Trial 29 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.2364468969410445, 'C': 8.310234949634078e-05}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:33:15,387] Trial 30 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.5621411310548077, 'C': 9.073794092354626e-07}. Best is trial 21 with value: 0.875982754969993.\n",
            "[I 2024-06-24 18:33:46,742] Trial 31 finished with value: 0.8763748364635555 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.40941406560108734, 'C': 0.15043229093931496}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:34:21,707] Trial 32 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.32214424947097614, 'C': 6.647523000521493}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:34:22,925] Trial 33 finished with value: 0.7663146574763318 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.453495606418725, 'C': 0.002567760640600478}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:34:23,007] Trial 34 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.32712955997988213, 'C': 3.661660570483232e-08}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:35:02,265] Trial 35 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.1533197175501294, 'C': 38.100298018164494}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:35:36,581] Trial 36 finished with value: 0.870662355870542 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.6076615436645691, 'C': 1.8434803287395392}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:35:51,081] Trial 37 finished with value: 0.783790562479326 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.40311403281910085, 'C': 0.01024874285161338}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:35:51,166] Trial 38 finished with value: 0.767786055252772 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.03373088825088133, 'C': 1.0380044905104906e-10}. Best is trial 31 with value: 0.8763748364635555.\n",
            "[I 2024-06-24 18:36:20,769] Trial 39 finished with value: 0.8738129492848735 and parameters: {'classifier': 'LogisticRegression', 'l1_ratio': 0.26440879223682745, 'C': 0.17074865800406652}. Best is trial 31 with value: 0.8763748364635555.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenTrial(number=31, state=TrialState.COMPLETE, values=[0.8763748364635555], datetime_start=datetime.datetime(2024, 6, 24, 18, 33, 15, 389085), datetime_complete=datetime.datetime(2024, 6, 24, 18, 33, 46, 742519), params={'classifier': 'LogisticRegression', 'l1_ratio': 0.40941406560108734, 'C': 0.15043229093931496}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'classifier': CategoricalDistribution(choices=('LogisticRegression',)), 'l1_ratio': FloatDistribution(high=1.0, log=False, low=0.0, step=None), 'C': FloatDistribution(high=1000.0, log=True, low=1e-10, step=None)}, trial_id=31, value=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xfIPpy8jb93d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# metricas\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "params = {\n",
        "    'l1_ratio': study.best_trial.params['l1_ratio'],\n",
        "    'C': study.best_trial.params['C'],\n",
        "    'max_iter': 5000,\n",
        "    'solver': 'saga',\n",
        "    'penalty': 'elasticnet',\n",
        "}\n",
        "\n",
        "model = LogisticRegression(**params)\n",
        "# Se entrena para guardar el artefacto\n",
        "model.fit(X_1, y_1)\n",
        "\n",
        "auc_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='roc_auc')\n",
        "wF1_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='f1_weighted')\n",
        "precision_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='precision_weighted')\n",
        "recall_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='recall_weighted')\n",
        "accuracy_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='accuracy')\n",
        "\n",
        "print(f'F1 ponderado: {np.round(wF1_score.mean(), 3)}. Garces et. al. : 0.900')\n",
        "print(f'Precisión: {np.round(precision_score.mean(), 3)}. Garces et. al. : 0.899')\n",
        "print(f'Recall: {np.round(recall_score.mean(), 3)}. Garces et. al. : 0.903')\n",
        "print(f'Accuracy: {np.round(accuracy_score.mean(), 3)}. Garces et. al. : 0.903')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj0GYFWyPPsc",
        "outputId": "f67dd673-6539-4bd6-9abf-f9eff0548d5a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 ponderado: 0.88. Garces et. al. : 0.900\n",
            "Precisión: 0.893. Garces et. al. : 0.899\n",
            "Recall: 0.896. Garces et. al. : 0.903\n",
            "Accuracy: 0.896. Garces et. al. : 0.903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "7sHoVthWDs4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptado de https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_simple.py\n",
        "\n",
        "import optuna\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVM\"])\n",
        "\n",
        "    if classifier_name == \"SVM\":\n",
        "        C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
        "        kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
        "        classifier_obj = SVC(C=C, kernel=kernel)\n",
        "\n",
        "    score = cross_val_score(classifier_obj, X_1, y_1, n_jobs=-1, cv=5, scoring='f1_weighted')\n",
        "    f1_weighted = score.mean()\n",
        "    return f1_weighted\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=40)\n",
        "print(study.best_trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IESLqDnPDpxe",
        "outputId": "b9fa91a1-feff-441e-e2c6-c40b07a3515e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-24 21:07:21,373] A new study created in memory with name: no-name-3c72c88d-4b8b-4c9c-8895-4ee182d16514\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-06-24 21:08:04,296] Trial 0 finished with value: 0.8954104247298993 and parameters: {'classifier': 'SVM', 'C': 0.06447900747213135, 'kernel': 'linear'}. Best is trial 0 with value: 0.8954104247298993.\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-06-24 21:08:05,446] Trial 1 finished with value: 0.7932891847485761 and parameters: {'classifier': 'SVM', 'C': 64.95611261837219, 'kernel': 'poly'}. Best is trial 0 with value: 0.8954104247298993.\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-06-24 21:09:35,439] Trial 2 finished with value: 0.8954104247298993 and parameters: {'classifier': 'SVM', 'C': 0.12582274264379223, 'kernel': 'linear'}. Best is trial 0 with value: 0.8954104247298993.\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-06-24 21:09:35,708] Trial 3 finished with value: 0.767786055252772 and parameters: {'classifier': 'SVM', 'C': 0.006544032027429739, 'kernel': 'poly'}. Best is trial 0 with value: 0.8954104247298993.\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-06-24 21:09:36,327] Trial 4 finished with value: 0.767786055252772 and parameters: {'classifier': 'SVM', 'C': 0.7433944100772232, 'kernel': 'poly'}. Best is trial 0 with value: 0.8954104247298993.\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-06-24 21:09:47,444] Trial 5 finished with value: 0.8643830400029827 and parameters: {'classifier': 'SVM', 'C': 1929.800807857622, 'kernel': 'poly'}. Best is trial 0 with value: 0.8954104247298993.\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[I 2024-06-24 21:09:47,773] Trial 6 finished with value: 0.767786055252772 and parameters: {'classifier': 'SVM', 'C': 0.01066110887222379, 'kernel': 'rbf'}. Best is trial 0 with value: 0.8954104247298993.\n",
            "<ipython-input-15-4d1c9a8e2c70>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
            "[W 2024-06-24 21:48:16,087] Trial 7 failed with parameters: {'classifier': 'SVM', 'C': 214.9235309459675, 'kernel': 'linear'} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-15-4d1c9a8e2c70>\", line 15, in objective\n",
            "    score = cross_val_score(classifier_obj, X_1, y_1, n_jobs=-1, cv=5, scoring='f1_weighted')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
            "    results = parallel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 2007, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
            "    yield from self._retrieve()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1762, in _retrieve\n",
            "    time.sleep(0.01)\n",
            "KeyboardInterrupt\n",
            "[W 2024-06-24 21:48:16,091] Trial 7 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4d1c9a8e2c70>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-4d1c9a8e2c70>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mclassifier_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mf1_weighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1_weighted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejores parámetros\n",
        "study.best_trial.params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbfCTkCHOU3E",
        "outputId": "7720ebbf-2de0-4e0c-8d72-0dff2ddf86b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier': 'SVM', 'C': 0.06447900747213135, 'kernel': 'linear'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metricas\n",
        "\n",
        "params = {\n",
        "    'C': study.best_trial.params['C'],\n",
        "    'kernel': study.best_trial.params['kernel'],\n",
        "}\n",
        "\n",
        "model = SVC(**params)\n",
        "# Se entrena para guardar el artefacto\n",
        "model.fit(X_1, y_1)\n",
        "\n",
        "auc_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='roc_auc')\n",
        "wF1_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='f1_weighted')\n",
        "precision_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='precision_weighted')\n",
        "recall_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='recall_weighted')\n",
        "accuracy_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='accuracy')\n",
        "\n",
        "print(f'F1 ponderado: {np.round(wF1_score.mean(), 3)}. Garces et. al. : 0.900')\n",
        "print(f'Precisión: {np.round(precision_score.mean(), 3)}. Garces et. al. : 0.899')\n",
        "print(f'Recall: {np.round(recall_score.mean(), 3)}. Garces et. al. : 0.903')\n",
        "print(f'Accuracy: {np.round(accuracy_score.mean(), 3)}. Garces et. al. : 0.903')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aokWoZ0jDyjD",
        "outputId": "09fbe48c-6424-491d-dfa5-a80675889d19"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 ponderado: 0.893. Garces et. al. : 0.900\n",
            "Precisión: 0.91. Garces et. al. : 0.899\n",
            "Recall: 0.909. Garces et. al. : 0.903\n",
            "Accuracy: 0.909. Garces et. al. : 0.903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXLLrcqDjKnF"
      },
      "source": [
        "### Opcional: Registro de Experimento y Métricas en MLFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZF0neM7jKnF"
      },
      "outputs": [],
      "source": [
        "# Ejecutar el siguiente comando en terminal: mlflow ui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uXBkCZfjKnF",
        "outputId": "fe8237a1-62dc-4496-c3d0-0718a3df2834"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\types\\utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "Registered model 'base-randomforest-tuned' already exists. Creating a new version of this model...\n",
            "2024/06/17 17:58:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: base-randomforest-tuned, version 3\n",
            "Created version '3' of model 'base-randomforest-tuned'.\n"
          ]
        }
      ],
      "source": [
        "# Registro en MLFlow\n",
        "# Adaptado de https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html\n",
        "import mlflow\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
        "\n",
        "mlflow.set_experiment(\"Modelo de Prueba\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "    # Registro de hiperparámetros\n",
        "    mlflow.log_params(params)\n",
        "\n",
        "    # Registro de métricas\n",
        "    mlflow.log_metric(\"ROC_AUC\", auc_score.mean())\n",
        "    mlflow.log_metric(\"Weighted_F1\", wF1_score.mean())\n",
        "\n",
        "    # Etiquetas\n",
        "    mlflow.set_tag(\"Random Forest\", \"Modelo base\")\n",
        "\n",
        "    # Signature del modelo\n",
        "    signature = infer_signature(X_1, model.predict_proba(X_1)[:,1])\n",
        "\n",
        "    # Registro del modelo\n",
        "    model_info = mlflow.sklearn.log_model(\n",
        "        sk_model=model,\n",
        "        artifact_path=\"modelos_experimento\",\n",
        "        signature=signature,\n",
        "        input_example=X_1.head(),\n",
        "        registered_model_name=\"base-randomforest-tuned\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCPtbWLajKnG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
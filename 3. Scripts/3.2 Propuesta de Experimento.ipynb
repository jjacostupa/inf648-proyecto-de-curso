{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código obtenido desde https://archive.ics.uci.edu/dataset/579/myocardial+infarction+complications\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# Extraer dataset\n",
    "myocardial_infarction_complications = fetch_ucirepo(id=579);\n",
    "\n",
    "# Data (como DataFrames de Pandas) \n",
    "X = myocardial_infarction_complications.data.features \n",
    "y = myocardial_infarction_complications.data.targets \n",
    "\n",
    "# Metadata \n",
    "# print(myocardial_infarction_complications.metadata) \n",
    "\n",
    "# Información de variables \n",
    "# print(myocardial_infarction_complications.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingeniería de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de variables y target\n",
    "X_1 = X.copy()\n",
    "X_1 = X_1.fillna(-1)\n",
    "\n",
    "y_1 = y['LET_IS']!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables: Se utiliza un Arbol de decisión que busque identificar todas las variables necesarias \n",
    "# para identificar completamente cada elemento del target.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "feature_selection_model = DecisionTreeClassifier(random_state=123)\n",
    "feature_selection_model.fit(X_1, y_1)\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_1.columns,\n",
    "    'Importance': feature_selection_model.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha reducido el número de variables de 111 a 58.\n"
     ]
    }
   ],
   "source": [
    "# Las variables que no tienen importancia 0, se descartan.\n",
    "features_to_delete = feature_importances.query('Importance==0')['Feature'].values\n",
    "X_1.drop(columns=features_to_delete, inplace=True)\n",
    "print(f'Se ha reducido el número de variables de {X.shape[1]} a {X_1.shape[1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-06-17 17:55:19,722] A new study created in memory with name: no-name-3fcaf9aa-381e-4026-aaec-fb0e16b85121\n",
      "[I 2024-06-17 17:55:22,795] Trial 0 finished with value: 0.767786055252772 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, 'rf_n_estimators': 217, 'rf_min_samples_leaf': 84, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.767786055252772.\n",
      "[I 2024-06-17 17:55:25,081] Trial 1 finished with value: 0.8950814719085767 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 5, 'rf_n_estimators': 306, 'rf_min_samples_leaf': 38, 'rf_criterion': 'log_loss'}. Best is trial 1 with value: 0.8950814719085767.\n",
      "[I 2024-06-17 17:55:26,644] Trial 2 finished with value: 0.8950814719085767 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 72, 'rf_min_samples_leaf': 26, 'rf_criterion': 'gini'}. Best is trial 1 with value: 0.8950814719085767.\n",
      "[I 2024-06-17 17:55:26,889] Trial 3 finished with value: 0.8924443826768463 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 83, 'rf_min_samples_leaf': 47, 'rf_criterion': 'gini'}. Best is trial 1 with value: 0.8950814719085767.\n",
      "[I 2024-06-17 17:55:27,154] Trial 4 finished with value: 0.8959177590784491 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 98, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial 4 with value: 0.8959177590784491.\n",
      "[I 2024-06-17 17:55:27,313] Trial 5 finished with value: 0.8959177590784491 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 44, 'rf_min_samples_leaf': 12, 'rf_criterion': 'entropy'}. Best is trial 4 with value: 0.8959177590784491.\n",
      "[I 2024-06-17 17:55:27,472] Trial 6 finished with value: 0.90386346888075 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 45, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 6 with value: 0.90386346888075.\n",
      "[I 2024-06-17 17:55:27,792] Trial 7 finished with value: 0.8955935541501873 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 112, 'rf_min_samples_leaf': 17, 'rf_criterion': 'entropy'}. Best is trial 6 with value: 0.90386346888075.\n",
      "[I 2024-06-17 17:55:28,150] Trial 8 finished with value: 0.8959177590784491 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 132, 'rf_min_samples_leaf': 9, 'rf_criterion': 'log_loss'}. Best is trial 6 with value: 0.90386346888075.\n",
      "[I 2024-06-17 17:55:28,289] Trial 9 finished with value: 0.8822499250122157 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7, 'rf_n_estimators': 37, 'rf_min_samples_leaf': 42, 'rf_criterion': 'log_loss'}. Best is trial 6 with value: 0.90386346888075.\n",
      "[I 2024-06-17 17:55:28,432] Trial 10 finished with value: 0.8947765641542536 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 3, 'rf_n_estimators': 24, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 6 with value: 0.90386346888075.\n",
      "[I 2024-06-17 17:55:28,621] Trial 11 finished with value: 0.9046311556294023 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 47, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:28,748] Trial 12 finished with value: 0.8995724566426888 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 20, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:28,932] Trial 13 finished with value: 0.9007759856403995 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 46, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:29,122] Trial 14 finished with value: 0.9022673398365546 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 57, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:29,254] Trial 15 finished with value: 0.9026271082284607 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 29, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:29,685] Trial 16 finished with value: 0.9019334669577456 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 164, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:29,900] Trial 17 finished with value: 0.8966001566305597 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 61, 'rf_min_samples_leaf': 8, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:30,978] Trial 18 finished with value: 0.8950814719085767 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 481, 'rf_min_samples_leaf': 16, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:31,176] Trial 19 finished with value: 0.9042838121105147 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 32, 'rf_min_samples_leaf': 4, 'rf_criterion': 'log_loss'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:31,318] Trial 20 finished with value: 0.8948564145567639 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 32, 'rf_min_samples_leaf': 11, 'rf_criterion': 'log_loss'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:31,498] Trial 21 finished with value: 0.9038523170478066 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 48, 'rf_min_samples_leaf': 4, 'rf_criterion': 'log_loss'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:31,627] Trial 22 finished with value: 0.8959177590784491 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 27, 'rf_min_samples_leaf': 6, 'rf_criterion': 'log_loss'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:31,780] Trial 23 finished with value: 0.9038523170478066 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 37, 'rf_min_samples_leaf': 4, 'rf_criterion': 'log_loss'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:31,888] Trial 24 finished with value: 0.8987412292264325 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 20, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 11 with value: 0.9046311556294023.\n",
      "[I 2024-06-17 17:55:32,032] Trial 25 finished with value: 0.9046656463038818 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 37, 'rf_min_samples_leaf': 3, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:32,258] Trial 26 finished with value: 0.900341887409111 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 69, 'rf_min_samples_leaf': 3, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:32,385] Trial 27 finished with value: 0.897555368479717 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 35, 'rf_min_samples_leaf': 6, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:32,502] Trial 28 finished with value: 0.8950814719085767 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 24, 'rf_min_samples_leaf': 10, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:32,702] Trial 29 finished with value: 0.767786055252772 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7, 'rf_n_estimators': 56, 'rf_min_samples_leaf': 90, 'rf_criterion': 'gini'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:32,966] Trial 30 finished with value: 0.8950814719085767 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 87, 'rf_min_samples_leaf': 21, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:33,115] Trial 31 finished with value: 0.9031116317858647 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 42, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:33,295] Trial 32 finished with value: 0.8977507948854377 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 54, 'rf_min_samples_leaf': 7, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:33,413] Trial 33 finished with value: 0.9006859524189194 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 30, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:33,564] Trial 34 finished with value: 0.9008815850091032 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 41, 'rf_min_samples_leaf': 3, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:33,682] Trial 35 finished with value: 0.8890901081574618 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 25, 'rf_min_samples_leaf': 31, 'rf_criterion': 'gini'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:33,891] Trial 36 finished with value: 0.8959177590784491 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 73, 'rf_min_samples_leaf': 13, 'rf_criterion': 'entropy'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:34,631] Trial 37 finished with value: 0.8959177590784491 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 5, 'rf_n_estimators': 319, 'rf_min_samples_leaf': 6, 'rf_criterion': 'log_loss'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:34,802] Trial 38 finished with value: 0.767786055252772 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 50, 'rf_min_samples_leaf': 67, 'rf_criterion': 'gini'}. Best is trial 25 with value: 0.9046656463038818.\n",
      "[I 2024-06-17 17:55:35,141] Trial 39 finished with value: 0.8996504771786491 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 116, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 25 with value: 0.9046656463038818.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=25, state=1, values=[0.9046656463038818], datetime_start=datetime.datetime(2024, 6, 17, 17, 55, 31, 888193), datetime_complete=datetime.datetime(2024, 6, 17, 17, 55, 32, 32909), params={'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 37, 'rf_min_samples_leaf': 3, 'rf_criterion': 'log_loss'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'classifier': CategoricalDistribution(choices=('RandomForest',)), 'rf_max_depth': IntDistribution(high=15, log=False, low=3, step=1), 'rf_n_estimators': IntDistribution(high=500, log=True, low=20, step=1), 'rf_min_samples_leaf': IntDistribution(high=100, log=True, low=3, step=1), 'rf_criterion': CategoricalDistribution(choices=('entropy', 'gini', 'log_loss'))}, trial_id=25, value=None)\n"
     ]
    }
   ],
   "source": [
    "# Adaptado de https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_simple.py\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"RandomForest\"])\n",
    "    if classifier_name == \"RandomForest\":\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 3, 15, log=False)\n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 20, 500, log=True)\n",
    "        rf_min_samples_leaf = trial.suggest_int(\"rf_min_samples_leaf\", 3, 100, log=True)\n",
    "        rf_criterion = trial.suggest_categorical(\"rf_criterion\", [\"entropy\",\"gini\",\"log_loss\"])\n",
    "        classifier_obj = RandomForestClassifier(\n",
    "            max_depth=rf_max_depth,\n",
    "            n_estimators=rf_n_estimators,\n",
    "            min_samples_leaf=rf_min_samples_leaf,\n",
    "            criterion=rf_criterion,\n",
    "            random_state=123,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    score = cross_val_score(classifier_obj, X_1, y_1, n_jobs=-1, cv=5, scoring='f1_weighted')\n",
    "    f1_weighted = score.mean()\n",
    "    return f1_weighted\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'RandomForest',\n",
       " 'rf_max_depth': 10,\n",
       " 'rf_n_estimators': 37,\n",
       " 'rf_min_samples_leaf': 3,\n",
       " 'rf_criterion': 'log_loss'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mejores parámetros\n",
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 58)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 ponderado: 0.906. Garces et. al. : 0.900\n",
      "Precisión: 0.92. Garces et. al. : 0.899\n",
      "Recall: 0.918. Garces et. al. : 0.903\n",
      "Accuracy: 0.918. Garces et. al. : 0.903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "kf = KFold(n_splits=N_FOLDS, random_state=123, shuffle=True)\n",
    "y_hat_rf = np.zeros(len(X_1))\n",
    "\n",
    "params = {\n",
    "    'max_depth': study.best_trial.params['rf_max_depth'],\n",
    "    'n_estimators': study.best_trial.params['rf_n_estimators'],\n",
    "    'min_samples_leaf': study.best_trial.params['rf_min_samples_leaf'],\n",
    "    'criterion': study.best_trial.params['rf_criterion'],\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 123,\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(**params)\n",
    "# Se entrena para guardar el artefacto\n",
    "model.fit(X_1, y_1)\n",
    "\n",
    "auc_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='roc_auc')\n",
    "wF1_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='f1_weighted')\n",
    "precision_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='precision_weighted')\n",
    "recall_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='recall_weighted')\n",
    "accuracy_score = cross_val_score(model, X_1, y_1, n_jobs=-1, cv=10, scoring='accuracy')\n",
    "\n",
    "print(f'F1 ponderado: {np.round(wF1_score.mean(), 3)}. Garces et. al. : 0.900')\n",
    "print(f'Precisión: {np.round(precision_score.mean(), 3)}. Garces et. al. : 0.899')\n",
    "print(f'Recall: {np.round(recall_score.mean(), 3)}. Garces et. al. : 0.903')\n",
    "print(f'Accuracy: {np.round(accuracy_score.mean(), 3)}. Garces et. al. : 0.903')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional: Registro de Experimento y Métricas en MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el siguiente comando en terminal: mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\types\\utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'base-randomforest-tuned' already exists. Creating a new version of this model...\n",
      "2024/06/17 17:58:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: base-randomforest-tuned, version 3\n",
      "Created version '3' of model 'base-randomforest-tuned'.\n"
     ]
    }
   ],
   "source": [
    "# Registro en MLFlow\n",
    "# Adaptado de https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "\n",
    "mlflow.set_experiment(\"Modelo de Prueba\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Registro de hiperparámetros\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Registro de métricas\n",
    "    mlflow.log_metric(\"ROC_AUC\", auc_score.mean())\n",
    "    mlflow.log_metric(\"Weighted_F1\", wF1_score.mean())\n",
    "\n",
    "    # Etiquetas\n",
    "    mlflow.set_tag(\"Random Forest\", \"Modelo base\")\n",
    "\n",
    "    # Signature del modelo\n",
    "    signature = infer_signature(X_1, model.predict_proba(X_1)[:,1])\n",
    "\n",
    "    # Registro del modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"modelos_experimento\",\n",
    "        signature=signature,\n",
    "        input_example=X_1.head(),\n",
    "        registered_model_name=\"base-randomforest-tuned\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

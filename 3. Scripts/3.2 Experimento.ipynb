{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código obtenido desde https://archive.ics.uci.edu/dataset/579/myocardial+infarction+complications\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# Extraer dataset\n",
    "myocardial_infarction_complications = fetch_ucirepo(id=579);\n",
    "\n",
    "# Data (como DataFrames de Pandas) \n",
    "X = myocardial_infarction_complications.data.features \n",
    "y = myocardial_infarction_complications.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingeniería de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de variables y target\n",
    "X_1 = X.copy()\n",
    "\n",
    "y_1 = y['LET_IS']!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables: Se utiliza un Arbol de decisión que busque identificar todas las variables necesarias \n",
    "# para identificar completamente cada elemento del target.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "feature_selection_model = DecisionTreeClassifier(random_state=123)\n",
    "feature_selection_model.fit(X_1, y_1)\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_1.columns,\n",
    "    'Importance': feature_selection_model.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha reducido el número de variables de 111 a 48.\n"
     ]
    }
   ],
   "source": [
    "# Las variables que no tienen importancia 0, se descartan.\n",
    "features_to_delete = feature_importances.query('Importance==0')['Feature'].values\n",
    "X_1.drop(columns=features_to_delete, inplace=True)\n",
    "print(f'Se ha reducido el número de variables de {X.shape[1]} a {X_1.shape[1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 15:03:16,340] A new study created in memory with name: no-name-ad29b486-f8a0-495c-8c31-036201e72390\n",
      "[I 2024-06-17 15:03:16,835] Trial 0 finished with value: 0.905521420367559 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 154, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:16,955] Trial 1 finished with value: 0.9006321513482256 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 24, 'rf_min_samples_leaf': 7, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:17,403] Trial 2 finished with value: 0.767786055252772 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 190, 'rf_min_samples_leaf': 100, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:17,563] Trial 3 finished with value: 0.8943308340084994 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 3, 'rf_n_estimators': 53, 'rf_min_samples_leaf': 8, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:18,177] Trial 4 finished with value: 0.8960464748012255 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 4, 'rf_n_estimators': 236, 'rf_min_samples_leaf': 19, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:18,409] Trial 5 finished with value: 0.8962812602738204 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 3, 'rf_n_estimators': 77, 'rf_min_samples_leaf': 21, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:18,656] Trial 6 finished with value: 0.9000440992165597 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 83, 'rf_min_samples_leaf': 10, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:18,898] Trial 7 finished with value: 0.9047707235652096 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 77, 'rf_min_samples_leaf': 3, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:19,521] Trial 8 finished with value: 0.7786787893535253 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 292, 'rf_min_samples_leaf': 82, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:19,770] Trial 9 finished with value: 0.9037239402262236 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 92, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:20,222] Trial 10 finished with value: 0.9044712132497535 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 165, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:20,382] Trial 11 finished with value: 0.9015879330551206 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7, 'rf_n_estimators': 41, 'rf_min_samples_leaf': 3, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:21,334] Trial 12 finished with value: 0.9009585745111852 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, 'rf_n_estimators': 433, 'rf_min_samples_leaf': 4, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:21,687] Trial 13 finished with value: 0.9038335378442456 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 125, 'rf_min_samples_leaf': 5, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:21,846] Trial 14 finished with value: 0.8920149785842275 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 44, 'rf_min_samples_leaf': 41, 'rf_criterion': 'gini'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:22,169] Trial 15 finished with value: 0.8993445112600883 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'rf_n_estimators': 123, 'rf_min_samples_leaf': 12, 'rf_criterion': 'entropy'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:22,276] Trial 16 finished with value: 0.8977975250674367 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, 'rf_n_estimators': 20, 'rf_min_samples_leaf': 5, 'rf_criterion': 'log_loss'}. Best is trial 0 with value: 0.905521420367559.\n",
      "[I 2024-06-17 15:03:22,467] Trial 17 finished with value: 0.9069301551971956 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 62, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:23,284] Trial 18 finished with value: 0.8935056944654187 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 367, 'rf_min_samples_leaf': 32, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:23,414] Trial 19 finished with value: 0.8986089595176494 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 13, 'rf_n_estimators': 30, 'rf_min_samples_leaf': 13, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:23,605] Trial 20 finished with value: 0.9060484072418384 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 57, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:23,777] Trial 21 finished with value: 0.9060484072418384 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 57, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:23,954] Trial 22 finished with value: 0.9068687982898321 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 54, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:24,093] Trial 23 finished with value: 0.9047170153894545 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 34, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:24,283] Trial 24 finished with value: 0.9058809835983098 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'rf_n_estimators': 61, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:24,433] Trial 25 finished with value: 0.9001073438883779 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 43, 'rf_min_samples_leaf': 8, 'rf_criterion': 'entropy'}. Best is trial 17 with value: 0.9069301551971956.\n",
      "[I 2024-06-17 15:03:24,636] Trial 26 finished with value: 0.9095447747758685 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 65, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:24,944] Trial 27 finished with value: 0.9060145847352464 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7, 'rf_n_estimators': 115, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:25,140] Trial 28 finished with value: 0.9022072395051746 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 5, 'rf_n_estimators': 67, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:25,271] Trial 29 finished with value: 0.9015068112292669 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 33, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:25,571] Trial 30 finished with value: 0.9039332815749941 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 7, 'rf_n_estimators': 110, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:25,746] Trial 31 finished with value: 0.905777993081205 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 53, 'rf_min_samples_leaf': 4, 'rf_criterion': 'entropy'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:25,947] Trial 32 finished with value: 0.9066388682554551 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 69, 'rf_min_samples_leaf': 5, 'rf_criterion': 'entropy'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:26,210] Trial 33 finished with value: 0.903630602140568 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 96, 'rf_min_samples_leaf': 6, 'rf_criterion': 'entropy'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:26,412] Trial 34 finished with value: 0.9067146419852694 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 9, 'rf_n_estimators': 69, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:26,573] Trial 35 finished with value: 0.9012809454038232 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 12, 'rf_n_estimators': 47, 'rf_min_samples_leaf': 9, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:26,693] Trial 36 finished with value: 0.9013530220244592 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 27, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:27,060] Trial 37 finished with value: 0.9049820447528241 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 10, 'rf_n_estimators': 141, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:27,314] Trial 38 finished with value: 0.895038697034041 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 83, 'rf_min_samples_leaf': 17, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n",
      "[I 2024-06-17 15:03:27,482] Trial 39 finished with value: 0.8953890382114394 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 14, 'rf_n_estimators': 38, 'rf_min_samples_leaf': 24, 'rf_criterion': 'gini'}. Best is trial 26 with value: 0.9095447747758685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=26, state=1, values=[0.9095447747758685], datetime_start=datetime.datetime(2024, 6, 17, 15, 3, 24, 433202), datetime_complete=datetime.datetime(2024, 6, 17, 15, 3, 24, 636443), params={'classifier': 'RandomForest', 'rf_max_depth': 8, 'rf_n_estimators': 65, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'classifier': CategoricalDistribution(choices=('RandomForest',)), 'rf_max_depth': IntDistribution(high=15, log=False, low=3, step=1), 'rf_n_estimators': IntDistribution(high=500, log=True, low=20, step=1), 'rf_min_samples_leaf': IntDistribution(high=100, log=True, low=3, step=1), 'rf_criterion': CategoricalDistribution(choices=('entropy', 'gini', 'log_loss'))}, trial_id=26, value=None)\n"
     ]
    }
   ],
   "source": [
    "# Adaptado de https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_simple.py\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"RandomForest\"])\n",
    "    if classifier_name == \"RandomForest\":\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 3, 15, log=False)\n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 20, 500, log=True)\n",
    "        rf_min_samples_leaf = trial.suggest_int(\"rf_min_samples_leaf\", 3, 100, log=True)\n",
    "        rf_criterion = trial.suggest_categorical(\"rf_criterion\", [\"entropy\",\"gini\",\"log_loss\"])\n",
    "        classifier_obj = RandomForestClassifier(\n",
    "            max_depth=rf_max_depth,\n",
    "            n_estimators=rf_n_estimators,\n",
    "            min_samples_leaf=rf_min_samples_leaf,\n",
    "            criterion=rf_criterion,\n",
    "            random_state=123,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    score = cross_val_score(classifier_obj, X_1, y_1, n_jobs=-1, cv=5, scoring='f1_weighted')\n",
    "    f1_weighted = score.mean()\n",
    "    return f1_weighted\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'RandomForest',\n",
       " 'rf_max_depth': 8,\n",
       " 'rf_n_estimators': 65,\n",
       " 'rf_min_samples_leaf': 3,\n",
       " 'rf_criterion': 'gini'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "kf = KFold(n_splits=N_FOLDS, random_state=123, shuffle=True)\n",
    "y_hat_rf = np.zeros(len(X_1))\n",
    "\n",
    "params = {\n",
    "    'max_depth': study.best_trial.params['rf_max_depth'],\n",
    "    'n_estimators': study.best_trial.params['rf_n_estimators'],\n",
    "    'min_samples_leaf': study.best_trial.params['rf_min_samples_leaf'],\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 123,\n",
    "    'criterion': 'entropy',\n",
    "}\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(X)):\n",
    "    X_train = X_1.iloc[train_index, :]\n",
    "    y_train = y_1.iloc[train_index]\n",
    "    X_valid = X_1.iloc[valid_index, :]\n",
    "    y_valid = y_1.iloc[valid_index]\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_hat_valid = model.predict_proba(X_valid)[:,1]\n",
    "    y_hat_rf[valid_index] = y_hat_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC : 0.9312553097539372.\n",
      "F1 ponderado: 0.905658250855685.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "auc_score = roc_auc_score(y_1, y_hat_rf)\n",
    "wF1_score = f1_score(y_1, y_hat_rf>=0.5, average='weighted')\n",
    "\n",
    "print(f'ROC-AUC : {auc_score}.')\n",
    "print(f'F1 ponderado: {wF1_score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional: Registro de Experimento y Métricas en MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el siguiente comando en terminal: mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'base-randomforest-tuned'.\n",
      "2024/06/17 15:08:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: base-randomforest-tuned, version 1\n",
      "Created version '1' of model 'base-randomforest-tuned'.\n"
     ]
    }
   ],
   "source": [
    "# Registro en MLFlow\n",
    "# Adaptado de https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "\n",
    "mlflow.set_experiment(\"Modelo de Prueba\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Registro de hiperparámetros\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Registro de métricas\n",
    "    mlflow.log_metric(\"ROC_AUC\", auc_score)\n",
    "    mlflow.log_metric(\"Weighted_F1\", wF1_score)\n",
    "\n",
    "    # Etiquetas\n",
    "    mlflow.set_tag(\"Random Forest\", \"Modelo base\")\n",
    "\n",
    "    # Signature del modelo\n",
    "    signature = infer_signature(X_train, model.predict_proba(X_train)[:,1])\n",
    "\n",
    "    # Registro del modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"modelos_experimento\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(),\n",
    "        registered_model_name=\"base-randomforest-tuned\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
